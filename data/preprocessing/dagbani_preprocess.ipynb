{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ccd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Special Dagbani character replacements\n",
    "replacements = {\n",
    "    \"\\u0002\": \"ɔ\",\n",
    "    \"\\u0003\": \"ŋ\",\n",
    "    \"\\u0004\": \"ɛ\",\n",
    "    \"\\u0005\": \"ɣ\",\n",
    "}\n",
    "\n",
    "# To clean up the extracted text from PDF\n",
    "def clean_pdf_text(raw):\n",
    "    for unknown, known in replacements.items():\n",
    "        raw = raw.replace(unknown, known)\n",
    "\n",
    "    cleaned = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', raw)\n",
    "\n",
    "    cleaned = unicodedata.normalize(\"NFC\", cleaned)\n",
    "\n",
    "    cleaned = cleaned.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
    "\n",
    "    cleaned = re.sub(r\"\\(?\\d+:\\d+\\)?|\\d+\", \"\", cleaned)\n",
    "\n",
    "    cleaned = re.sub(r\"\\s{2,}\", \" \", cleaned)\n",
    "    cleaned = cleaned.replace(\"', '\", \" \")\n",
    "\n",
    "    return cleaned.strip()\n",
    "\n",
    "\n",
    "english_stopwords = {\n",
    "    \"the\", \"and\", \"is\", \"in\", \"of\", \"to\", \"that\", \"for\", \"on\", \"with\", \"as\",\n",
    "    \"bible\", \"watchtower\", \"awake\", \"jw.org\", \"jw\", \"org\"\n",
    "}\n",
    "\n",
    "# To remove lines containing any English stopwords\n",
    "def remove_english_words(lines):\n",
    "    filtered = []\n",
    "    for line in lines:\n",
    "        words = set(re.findall(r\"[a-zA-Z]+\", line.lower()))\n",
    "        if not (words & english_stopwords):\n",
    "            filtered.append(line)\n",
    "    return filtered\n",
    "\n",
    "def final_clean(lines):\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        # 1. Collapse space-separated letters: \"b a i b u l\" -> \"baibul\"\n",
    "        line = re.sub(r\"(?:\\b\\w\\s)+\\w\\b\", lambda m: m.group(0).replace(\" \", \"\"), line)\n",
    "\n",
    "        # 2. Remove stray symbols (˙ ’ , ? ! etc.) except Dagbani letters\n",
    "        line = re.sub(r\"[^a-zA-Zɔɛŋɣ\\s]\", \"\", line)\n",
    "\n",
    "        # 3. Normalize multiple spaces\n",
    "        line = re.sub(r\"\\s{2,}\", \" \", line).strip()\n",
    "\n",
    "        # 4. Drop if line is empty\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # 5. Stopword filtering\n",
    "        words = set(re.findall(r\"[a-zA-Zɔɛŋɣ]+\", line.lower()))\n",
    "        if words & english_stopwords:\n",
    "            continue\n",
    "\n",
    "        cleaned.append(line)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "doc = fitz.open(\"/content/lffi_DGB.pdf\")\n",
    "all_text = \" \".join(clean_pdf_text(page.get_text()) for page in doc)\n",
    "\n",
    "cleaned_lines = [line.lower() for line in all_text.split(\".\") if line.strip()]\n",
    "\n",
    "cleaned_lines = remove_english_words(cleaned_lines)\n",
    "\n",
    "cleaned_lines = final_clean(cleaned_lines)\n",
    "\n",
    "data = {\"lang\": \"dagbani\", \"data\": cleaned_lines}\n",
    "with open(\"dagbani_corpus.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
